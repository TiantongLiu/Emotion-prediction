{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: \n",
      "accuracy: 0.6400680947652149\n",
      "kappa: 0.5196751764096217\n",
      "roc_auc nan\n",
      "precision 0.6292227746845809\n",
      "recall 0.6403597166351689\n",
      "f1_score 0.6292243453000139\n",
      "\n",
      "LogisticRegression: \n",
      "accuracy: 0.5504738260746206\n",
      "kappa: 0.4007456706359318\n",
      "roc_auc nan\n",
      "precision 0.5469005099971928\n",
      "recall 0.5523589599528677\n",
      "f1_score 0.5419463784781235\n",
      "\n",
      "GaussianNB: \n",
      "accuracy: 0.4758760107816712\n",
      "kappa: 0.3006099501265076\n",
      "roc_auc nan\n",
      "precision 0.506832946827224\n",
      "recall 0.4754553994483478\n",
      "f1_score 0.43682097862145214\n",
      "\n",
      "Decision Tree: \n",
      "accuracy: 0.6720712157752874\n",
      "kappa: 0.5624960010421651\n",
      "roc_auc nan\n",
      "precision 0.6699361108241576\n",
      "recall 0.673232559001893\n",
      "f1_score 0.669732071795212\n",
      "\n",
      "Random Forest: \n",
      "accuracy: 0.7620499361611575\n",
      "kappa: 0.6820152469319527\n",
      "roc_auc nan\n",
      "precision 0.7584007825131938\n",
      "recall 0.7611372601804137\n",
      "f1_score 0.7584591849841076\n",
      "\n",
      "SVM: \n",
      "accuracy: 0.4393828911902398\n",
      "kappa: 0.25338023216797134\n",
      "roc_auc nan\n",
      "precision 0.4531853309361754\n",
      "recall 0.44050936891579473\n",
      "f1_score 0.42010615469132145\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np    \n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "from sklearn.neighbors import KNeighborsClassifier   \n",
    "from sklearn import svm  \n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "\n",
    "#from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from joblib import dump\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#import matplotlib.pyplot as plt\n",
    "#from sklearn.metrics import roc_curve, auc  ###计算roc和auc\n",
    "#rom sklearn import cross_validation\n",
    "#rom sklearn.model_selection import train_test_split\n",
    "\n",
    "# =============================================================================\n",
    "# feature_names = [    \n",
    "#     'area',    \n",
    "#     'perimeter',    \n",
    "#     'compactness',    \n",
    "#     'length of kernel',    \n",
    "#     'width of kernel',    \n",
    "#     'asymmetry coefficien',    \n",
    "#     'length of kernel groove',    \n",
    "# ]    \n",
    "# =============================================================================\n",
    "  \n",
    "COLOUR_FIGURE = False    \n",
    "  \n",
    "# =============================================================================\n",
    "# def load_csv_data(filename):     #读取文件，文件最后一列当成标签\n",
    "#     dataframe = pd.read_csv(filename)\n",
    "#     #dataframe = pd.read_csv(url,names=names)\n",
    "#     array = dataframe.values\n",
    "#     len1=dataframe.columns.size-1\n",
    "#     #names1 = dataframe.axes[1]\n",
    "#     #names = names1[0:12]\n",
    "#    # print(names)\n",
    "#     \n",
    "#     data = array[:,0:len1]\n",
    "#     #print(X.shape)\n",
    "#     labels = array[:,len1]\n",
    "#     return data, labels \n",
    "\n",
    "def load_csv_data(filename):     #读取文件，文件最后一列当成标签\n",
    "    dataframe = pd.read_csv(filename)\n",
    "    #dataframe = pd.read_csv(url,names=names)\n",
    "    array = dataframe.values\n",
    "    len1=dataframe.columns.size-1\n",
    "    #names1 = dataframe.axes[1]\n",
    "    #names = names1[0:12]\n",
    "   # print(names)\n",
    " \n",
    "    # 定义SMOTE模型，random_state相当于随机数种子的作用\n",
    "    \n",
    "    data = array[:,0:len1]\n",
    "    #print(X.shape)\n",
    "    labels = array[:,len1]\n",
    "    smo = SMOTE(random_state=42)\n",
    "    data, labels = smo.fit_sample(data, labels)\n",
    "    # 将标签二值化\n",
    "#    labels = label_binarize(y_smo, classes=[1,2,3,4])\n",
    "#    print(labels)\n",
    "        # 设置种类(共三种)\n",
    "    #print(labels.shape[1])\n",
    "    return data, labels \n",
    "\n",
    "# =============================================================================\n",
    "    #print(Y)\n",
    "# =============================================================================\n",
    "#     data = []    \n",
    "#     labels = []    \n",
    "#     datafile = open(filename)    \n",
    "#     for line in datafile:    \n",
    "#         fields = line.strip().split('\\t')    \n",
    "#         data.append([float(field) for field in fields[:-1]])    \n",
    "#         labels.append(fields[-1])     #文件最后一列当成标签\n",
    "#     data = np.array(data)    \n",
    "#     labels = np.array(labels)    \n",
    "#     return data, labels    \n",
    "# =============================================================================\n",
    "      \n",
    "# =============================================================================\n",
    "# def accuracy(test_labels, pred_lables):    \n",
    "#     correct = np.sum(test_labels == pred_lables)  #相等   \n",
    "#     n = len(test_labels)    \n",
    "#     return float(correct) / n    \n",
    "# =============================================================================\n",
    "def accuracy(result_set):  \n",
    "    ac_score=[]\n",
    "    ka_score=[]\n",
    "    roc_score=[]\n",
    "    pre_score=[]\n",
    "    rec_score=[]\n",
    "    f_score=[]\n",
    "    for result in result_set:\n",
    "        #print (labels[result[1]], result[0])\n",
    "        #ac=accuracy(labels[result[1]], result[0])  #labels[result[1]] 真实目标值, result[0] 预测目标值\n",
    "        # print(clf.score(labels[result[1]], result[0]))\n",
    "        #print(ac)\n",
    "        ac=accuracy_score(labels[result[1]], result[0])  #accuracy\n",
    "        ac_score.append(ac)\n",
    "        \n",
    "        ka=cohen_kappa_score(labels[result[1]], result[0])   #kappa\n",
    "        ka_score.append(ka)\n",
    "        \n",
    "        #score1=classification_report(labels[result[1]], result[0])   #precision, recall, f1,support\n",
    "        #print(score1)\n",
    "        \n",
    "        pre=precision_score(labels[result[1]], result[0], average='macro') \n",
    "        pre_score.append(pre)\n",
    "        \n",
    "        rec=recall_score(labels[result[1]], result[0], average='macro') \n",
    "        rec_score.append(rec)\n",
    "        \n",
    "        f1=f1_score(labels[result[1]], result[0], average='macro') \n",
    "        f_score.append(f1)\n",
    "        \n",
    "        #print(precision)\n",
    "        #print(len(score1))\n",
    "       # scores.append(score1)\n",
    "        #print(type(score1))\n",
    "        #print(score1[3][1])\n",
    "        #print(score1.index)\n",
    "        #precision=precision+score1['precision']['macro avg']\n",
    "        \n",
    "#        roc=roc_auc_score(labels[result[1]], result[2])\n",
    "#        roc_score.append(roc)\n",
    "        \n",
    "    #print(ac_score)\n",
    "    print('accuracy:',np.mean(ac_score))\n",
    "    #print(ka_score)\n",
    "    print('kappa:',np.mean(ka_score))\n",
    "    \n",
    "    print('roc_auc',np.mean(roc_score))\n",
    "    \n",
    "    print('precision',np.mean(pre_score))\n",
    "    print('recall',np.mean(rec_score))\n",
    "    print('f1_score',np.mean(f_score))\n",
    "    \n",
    "    #print(scores)\n",
    "    #print('classification_report:',np.mean(scores))\n",
    "#------------------------------------------------------------------------------  \n",
    "#K近邻  \n",
    "#------------------------------------------------------------------------------  \n",
    "def testKNN(features, labels):  \n",
    "    kf = KFold(n_splits=10, shuffle=True) #len(features)这个参数的意思是把（0，len(features)-1）之间的序列随机拆分成3份。\n",
    "    kf.get_n_splits(len(features))\n",
    "    clf = KNeighborsClassifier(n_neighbors=3)    \n",
    "    result_set = []\n",
    "    for train, test in kf.split(features):\n",
    "        #clf.fit(features[train], labels[train])  #训练\n",
    "       #通过decision_function()计算得到的y_score的值，用在roc_curve()函数中\n",
    "        #print(features[test])\n",
    "        y_score = clf.fit(features[train],labels[train]).predict_proba(features[test])  #训练\n",
    "        #print(y_scores.shape)\n",
    "        y_scores=y_score[:,1]\n",
    "        result=clf.predict(features[test])   #预测\n",
    "        result_set.append((result, test, y_scores))\n",
    "    return result_set\n",
    "    \n",
    "    #通过decision_function()计算得到的y_score的值，用在roc_curve()函数中\n",
    "  # y_score = svm.fit(features[train],labels[train]).decision_function(features[test])\n",
    "    \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "# =============================================================================\n",
    "#     fpr,tpr,threshold = roc_curve(labels[test], y_score) #计算真正率和假正率\n",
    "#     roc_auc = auc(fpr,tpr) #计算auc的值\n",
    "#     \n",
    "#     lw = 2\n",
    "#     plt.figure(figsize=(10,10))\n",
    "#     plt.plot(fpr, tpr, color='darkorange',\n",
    "#              lw=lw, label='ROC curve (area = %0.2f)' % roc_auc) #假正率为横坐标，真正率为纵坐标做曲线\n",
    "#     plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--') #画对角线y=x\n",
    "#     plt.xlim([0.0, 1.0])#  坐标值范围\n",
    "#     plt.ylim([0.0, 1.05])\n",
    "#     plt.xlabel('False Positive Rate')\n",
    "#     plt.ylabel('True Positive Rate')\n",
    "#     plt.title('Receiver operating characteristic example')\n",
    "#     plt.legend(loc=\"lower right\")  #显示label的位置\n",
    "#     plt.show()\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "  \n",
    "    \n",
    "\n",
    "#------------------------------------------------------------------------------  \n",
    "#逻辑回归  \n",
    "#------------------------------------------------------------------------------  \n",
    "def testLR(features, labels):  \n",
    "    kf = KFold(n_splits=10, shuffle=True)    \n",
    "    kf.get_n_splits(len(features))\n",
    "    clf = LogisticRegression(solver='liblinear')  \n",
    "    result_set = []\n",
    "#    result_set = [(clf.fit(features[train], labels[train]).predict(features[test]), test,clf.decision_function(features[test])) for train, test in kf.split(features)]    \n",
    "    for train, test in kf.split(features):\n",
    "        y_score = clf.fit(features[train],labels[train]).predict_proba(features[test])  #训练\n",
    "        y_scores=y_score[:,1]\n",
    "        result=clf.predict(features[test])   #预测\n",
    "        result_set.append((result, test, y_scores))\n",
    "    return result_set\n",
    " \n",
    "\n",
    "  \n",
    "#------------------------------------------------------------------------------  \n",
    "#朴素贝叶斯  \n",
    "#------------------------------------------------------------------------------  \n",
    "def testNaiveBayes(features, labels):  \n",
    "    kf = KFold(n_splits=10, shuffle=True)    \n",
    "    kf.get_n_splits(len(features))\n",
    "    clf = GaussianNB()  \n",
    "    result_set = []\n",
    "#    result_set = [(clf.fit(features[train], labels[train]).predict(features[test]), test,clf.decision_function(features[test])) for train, test in kf.split(features)]  \n",
    "    for train, test in kf.split(features):\n",
    "        y_score = clf.fit(features[train],labels[train]).predict_proba(features[test]) #训练\n",
    "        y_scores=y_score[:,1]\n",
    "        result=clf.predict(features[test])   #预测\n",
    "        result_set.append((result, test, y_scores))\n",
    "    return result_set\n",
    "  \n",
    "               \n",
    "#------------------------------------------------------------------------------  \n",
    "#--- 支持向量机  \n",
    "#------------------------------------------------------------------------------  \n",
    "def testSVM(features, labels):  \n",
    "    kf = KFold(n_splits=10, shuffle=True)    \n",
    "    kf.get_n_splits(len(features))\n",
    "    clf = svm.SVC(probability=True, gamma='auto')  \n",
    "    #result_set = [(clf.fit(features[train], labels[train]).predict(features[test]), test) for train, test in kf.split(features)]    \n",
    "    #score = [accuracy(labels[result[1]], result[0]) for result in result_set]    \n",
    "    #print(score)  \n",
    "    result_set = []\n",
    "    for train, test in kf.split(features):\n",
    "        y_score = clf.fit(features[train],labels[train]).predict_proba(features[test]) #训练\n",
    "        y_scores=y_score[:,1]\n",
    "        result=clf.predict(features[test])   #预测\n",
    "        result_set.append((result, test, y_scores))\n",
    "    return result_set\n",
    " \n",
    "  \n",
    "#------------------------------------------------------------------------------  \n",
    "#--- 决策树  \n",
    "#------------------------------------------------------------------------------  \n",
    "def testDecisionTree(features, labels):  \n",
    "    kf = KFold(n_splits=10, shuffle=True)    \n",
    "    kf.get_n_splits(len(features))\n",
    "    clf = DecisionTreeClassifier()  \n",
    "    #result_set = [(clf.fit(features[train], labels[train]).predict(features[test]), test) for train, test in kf.split(features)]    \n",
    "    #score = [accuracy(labels[result[1]], result[0]) for result in result_set]    \n",
    "    #print(score)  \n",
    "    result_set = []\n",
    "    for train, test in kf.split(features):\n",
    "        y_score = clf.fit(features[train],labels[train]).predict_proba(features[test]) #训练\n",
    "        y_scores=y_score[:,1]\n",
    "        result=clf.predict(features[test])   #预测\n",
    "        result_set.append((result, test, y_scores))\n",
    "    return result_set \n",
    "      \n",
    "#------------------------------------------------------------------------------  \n",
    "#--- 随机森林  \n",
    "#------------------------------------------------------------------------------  \n",
    "def testRandomForest(features, labels):  \n",
    "    kf = KFold(n_splits=10, shuffle=True)    \n",
    "    kf.get_n_splits(len(features))\n",
    "    clf = RandomForestClassifier(n_estimators=10)  \n",
    "    #result_set = [(clf.fit(features[train], labels[train]).predict(features[test]), test) for train, test in kf.split(features)]    \n",
    "    #score = [accuracy(labels[result[1]], result[0]) for result in result_set]    \n",
    "    #print(score)  \n",
    "    result_set = []\n",
    "    for train, test in kf.split(features):\n",
    "        y_score = clf.fit(features[train],labels[train]).predict_proba(features[test]) #训练\n",
    "        y_scores=y_score[:,1]\n",
    "        result=clf.predict(features[test])   #预测\n",
    "        result_set.append((result, test, y_scores))\n",
    "    return result_set\n",
    "  \n",
    "      \n",
    "if __name__ == '__main__':  \n",
    "#     features, labels = load_csv_data('/Users/yumh/Desktop/重要/第二课课程代码及数据文件/data./data/seeds_dataset.txt')\n",
    "    features, labels = load_csv_data(r'C:\\Users\\liutt\\Desktop\\data for paper\\achievement_emotion_training_data(1).csv') \n",
    "    #print(features)  \n",
    "    #print(labels)\n",
    "      \n",
    "       \n",
    "    print('KNN: \\r')  \n",
    "    accuracy(testKNN(features, labels))\n",
    "    print('\\r') \n",
    "    \n",
    "    print('LogisticRegression: \\r')  \n",
    "    accuracy(testLR(features, labels)) \n",
    "    print('\\r') \n",
    "       \n",
    "    print('GaussianNB: \\r')  \n",
    "    accuracy(testNaiveBayes(features, labels)) \n",
    "    print('\\r')   \n",
    "    \n",
    "    print('Decision Tree: \\r')  \n",
    "    accuracy(testDecisionTree(features, labels))\n",
    "    print('\\r') \n",
    "    \n",
    "    print('Random Forest: \\r')  \n",
    "    accuracy(testRandomForest(features, labels))\n",
    "    print('\\r') \n",
    "    \n",
    "    print('SVM: \\r')  \n",
    "    accuracy(testSVM(features, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-60abf460d402>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn_estimators\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m         \u001b[0mmse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'black'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np    \n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "from sklearn.neighbors import KNeighborsClassifier   \n",
    "from sklearn import svm  \n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from joblib import dump\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#import matplotlib.pyplot as plt\n",
    "#from sklearn.metrics import roc_curve, auc  ###计算roc和auc\n",
    "#rom sklearn import cross_validation\n",
    "#rom sklearn.model_selection import train_test_split\n",
    "\n",
    "# =============================================================================\n",
    "# feature_names = [    \n",
    "#     'area',    \n",
    "#     'perimeter',    \n",
    "#     'compactness',    \n",
    "#     'length of kernel',    \n",
    "#     'width of kernel',    \n",
    "#     'asymmetry coefficien',    \n",
    "#     'length of kernel groove',    \n",
    "# ]    \n",
    "# =============================================================================\n",
    "  \n",
    "COLOUR_FIGURE = False    \n",
    "  \n",
    "# =============================================================================\n",
    "# def load_csv_data(filename):     #读取文件，文件最后一列当成标签\n",
    "#     dataframe = pd.read_csv(filename)\n",
    "#     #dataframe = pd.read_csv(url,names=names)\n",
    "#     array = dataframe.values\n",
    "#     len1=dataframe.columns.size-1\n",
    "#     #names1 = dataframe.axes[1]\n",
    "#     #names = names1[0:12]\n",
    "#    # print(names)\n",
    "#     \n",
    "#     data = array[:,0:len1]\n",
    "#     #print(X.shape)\n",
    "#     labels = array[:,len1]\n",
    "#     return data, labels \n",
    "\n",
    "def load_csv_data(filename):     #读取文件，文件最后一列当成标签\n",
    "    dataframe = pd.read_csv(filename)\n",
    "    #dataframe = pd.read_csv(url,names=names)\n",
    "    array = dataframe.values\n",
    "    len1=dataframe.columns.size-1\n",
    "    #names1 = dataframe.axes[1]\n",
    "    #names = names1[0:12]\n",
    "   # print(names)\n",
    " \n",
    "    # 定义SMOTE模型，random_state相当于随机数种子的作用\n",
    "    \n",
    "    data = array[:,0:len1]\n",
    "    #print(X.shape)\n",
    "    labels = array[:,len1]\n",
    "    smo = SMOTE(random_state=42)\n",
    "    data, labels = smo.fit_sample(data, labels)\n",
    "    # 将标签二值化\n",
    "#    labels = label_binarize(y_smo, classes=[1,2,3,4])\n",
    "#    print(labels)\n",
    "        # 设置种类(共三种)\n",
    "    #print(labels.shape[1])\n",
    "    return data, labels \n",
    "\n",
    "# =============================================================================\n",
    "    #print(Y)\n",
    "# =============================================================================\n",
    "#     data = []    \n",
    "#     labels = []    \n",
    "#     datafile = open(filename)    \n",
    "#     for line in datafile:    \n",
    "#         fields = line.strip().split('\\t')    \n",
    "#         data.append([float(field) for field in fields[:-1]])    \n",
    "#         labels.append(fields[-1])     #文件最后一列当成标签\n",
    "#     data = np.array(data)    \n",
    "#     labels = np.array(labels)    \n",
    "#     return data, labels    \n",
    "# =============================================================================\n",
    "      \n",
    "# =============================================================================\n",
    "# def accuracy(test_labels, pred_lables):    \n",
    "#     correct = np.sum(test_labels == pred_lables)  #相等   \n",
    "#     n = len(test_labels)    \n",
    "#     return float(correct) / n    \n",
    "# =============================================================================\n",
    "def accuracy(result_set):  \n",
    "    ac_score=[]\n",
    "    ka_score=[]\n",
    "    roc_score=[]\n",
    "    pre_score=[]\n",
    "    rec_score=[]\n",
    "    f_score=[]\n",
    "    for result in result_set:\n",
    "        #print (labels[result[1]], result[0])\n",
    "        #ac=accuracy(labels[result[1]], result[0])  #labels[result[1]] 真实目标值, result[0] 预测目标值\n",
    "        # print(clf.score(labels[result[1]], result[0]))\n",
    "        #print(ac)\n",
    "        ac=accuracy_score(labels[result[1]], result[0])  #accuracy\n",
    "        ac_score.append(ac)\n",
    "        \n",
    "        ka=cohen_kappa_score(labels[result[1]], result[0])   #kappa\n",
    "        ka_score.append(ka)\n",
    "        \n",
    "        #score1=classification_report(labels[result[1]], result[0])   #precision, recall, f1,support\n",
    "        #print(score1)\n",
    "        \n",
    "        pre=precision_score(labels[result[1]], result[0], average='macro') \n",
    "        pre_score.append(pre)\n",
    "        \n",
    "        rec=recall_score(labels[result[1]], result[0], average='macro') \n",
    "        rec_score.append(rec)\n",
    "        \n",
    "        f1=f1_score(labels[result[1]], result[0], average='macro') \n",
    "        f_score.append(f1)\n",
    "        \n",
    "        #print(precision)\n",
    "        #print(len(score1))\n",
    "       # scores.append(score1)\n",
    "        #print(type(score1))\n",
    "        #print(score1[3][1])\n",
    "        #print(score1.index)\n",
    "        #precision=precision+score1['precision']['macro avg']\n",
    "        \n",
    "#        roc=roc_auc_score(labels[result[1]], result[2])\n",
    "#        roc_score.append(roc)\n",
    "        \n",
    "    #print(ac_score)\n",
    "    print('accuracy:',np.mean(ac_score))\n",
    "    #print(ka_score)\n",
    "    print('kappa:',np.mean(ka_score))\n",
    "    \n",
    "    print('roc_auc',np.mean(roc_score))\n",
    "    \n",
    "    print('precision',np.mean(pre_score))\n",
    "    print('recall',np.mean(rec_score))\n",
    "    print('f1_score',np.mean(f_score))\n",
    "    \n",
    "def testRandomForest(features, labels, n_estimators):  \n",
    "    kf = KFold(n_splits=10, shuffle=True)    \n",
    "    kf.get_n_splits(len(features))\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators)  \n",
    "    #result_set = [(clf.fit(features[train], labels[train]).predict(features[test]), test) for train, test in kf.split(features)]    \n",
    "    #score = [accuracy(labels[result[1]], result[0]) for result in result_set]    \n",
    "    #print(score)  \n",
    "    result_set = []\n",
    "    for train, test in kf.split(features):\n",
    "        y_score = clf.fit(features[train],labels[train]).predict_proba(features[test]) #训练\n",
    "        y_scores=y_score[:,1]\n",
    "        result=clf.predict(features[test])   #预测\n",
    "        result_set.append((result, test, y_scores))\n",
    "    return result_set\n",
    "  \n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
